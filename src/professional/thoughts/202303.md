# Thoughts of Mar. 2023


**20230305**

记录一下2月26日在Bring up 会议上的讲稿, 以及反馈

## Andes M0 BU proposal

=============
大家好, 今天借这个机会介绍一下System此前在Andes BB验证和A0验证中的一些具体案例经验和反思, 以及对M0 bring up中system任务的一些预期.

我们先看两个例子:

* 前端: Andes A0 两片级联收发功能
* 基带: BB与DSP数据交互实现DDM CFAR 目标

Andes级联收发功能点的基本要求包括slave芯片能够被master芯片LO驱动发射, 8通道能够通过PA/PS控制实现TDM/DDM波形, 两颗芯片ADC同步. 这些功能在设计阶段就有考量, 最终证明可以成立, 但过程比较久. 具体来说, 验证过程中遇到这些问题:

* Slave 芯片TX PA off问题: 驱动中寄存器操作错误 & slave读取配置与发射顺序错误
 - 11月9日报bug, 11月17日解决
* Slave 芯片TX PA/PS digital control问题: slave芯片相关PLL未使能, fmcw timing engine未工作.
 - 11月17日确认, 18日解决
* Slave 芯片ADC同步问题: ADC初始化相关驱动错误导致两颗芯片ADC同步机制未工作
 - 10月20日 system 提供首批lab测试结果; 驱动更新后 system迭代测试无果, 11月9日报bug, system提供稳定的bench测试方法; 11月25日解决; 12月1日system lab测试确认;

第二个例子是基带方面: DDM发射模式下一个真实目标造成多个CFAR 检出; Andes上这些检出的位置关系比较灵活, 没有通过BB实现匹配解算, 而考虑通过BB-DSP数据交互, 由DSP实现匹配, 并返回BB继续计算DOA.

* BB-DSP backdoor单元测试较早开展
 - 证明了功能设计成立
* 11月7日, 完成简单CFAR运算中的单次数据交互验证
 - 多次交互同步问题, 耗时问题
 - 随着CFAR算法更加复杂, BB-DSP 数据交互也发生变化
 - 如果在这个状态下向solution team交付, 很可能延误开发进度.
* 2月初, 规划了两片级联end to end中的数据交互验证; 2月底完成
* DSP算法真实实现及计算优化未开展
 - 当前基于伪代码 place holder验证.

即使针对这些验证阶段已经遇到过的问题, 是否有把握在M0 bring up阶段, 用一星期甚至更短的时间解决呢? 可能可以, 但必须利用芯片回来前的窗口做一些整理和计划, 充分利用此前的经验和积累. 这是我对Ricky提出的, 需要对bring up排定详细计划这个任务的理解.

==============

这两个例子中的一个共同问题是, **上游的模块设计没有问题, 但下游用户很难及时得到完整易用的功能**, 两者之间的系统集成层面存在一些缺失; Andes比Pro的新功能多一些, 暴露的问题也多一些. 我认为缺失的两个环节, 一个是Concept of operations, ConOps; 一个是交付与验收.

关于ConOps, NASA system engineer handbook这样描述:

"ConOps describes the system characteristics from an operational perspective and helps facilitate an understanding of the system goals and objectives and other stakeholder expectations. Examples would be the ConOps document, model, or a Design Reference Mission (DRM)."

(考虑介绍 MBC driver案例: 原理性验证不能替代功能验证, FW中断刷新fmcw buffer的耗时, FW限于内存问题仅支持少量脉冲波形, system不能向solution做完整交付)

关于交付验收, 我有一个粗略的印象: 在A0和FPGA验证中, 上游对于工作交付, 下游对于工作验收的重视程度和时间估计是总体偏少的, 比如默认一次性的文档交付可以完整地传递知识, 通常仅在debug时考虑上下游工程师协同工作的必要性; 比如下游部门排日程计划时, 可能只给验收接收工作留一天时间; 比如在任务列表的管理中, 一般重视DRI对进度的report, 较少对initializer的需求输入和验收方法提出更明确的需求.

ConOps作为一个事前环节, 从使用和操作者(而非设计)的角度描述系统的特性, 帮助各方统一理解. 交付验收作为事后环节, 确保就ConOps达成的一致得到落实, 将使用中的问题和分析及时地反馈到上游. 两者的缺失一般造成几个问题

* 下游给出验证任务及场景的定义较难, 上游收到的早期需求不明确
* 上游各自交付模块, 整体功能验收不足, 容易处在"基本完成, 无法使用"的状态
* 综合问题定位难
* 静态交付并不高效, 使用调试技巧仍然需要持续支持, 或容易丢失
* 协作关系的动态调整相对被动, 不能及时变"上游改下游测"的长循环为"上游改上游测"的短循环

对于Andes M0 BU而言, 两片级联Alpha solution可以作为ConOps的起点, 也适宜作为bring up验收的终点.

随着三月底前Alpha solution的设计逐渐清晰, 对功能点的划分和描述, 对相关交付验证的场景设计, 原理/可行性/依赖性分析也会逐渐丰富和完善.

例如当前开展的FPGA verification Phase 4, 就是针对Alpha solution的潜在需求, 验证性能较好的复杂CFAR调度流程的正确性和可行性. 完整的前端工作模式和测试条件, 也将根据Alpha solution调制和参数设计逐渐确定. 

system的工作重点是从FW/digital和Analog方面验收基带/前端功能, 完成系统验证并向solution 交付.

下面通过一些案例说明预期中前端和BB bring up阶段的工作内容和需求.

==============

前端案例: DDM旁瓣水平-移相器性能

在Alps测试, Alps Pro的设计和BU中我们对移相器的工作特性积累了不少了解. 对于Andes M0, 要完整地满足Alpha solution需要的8TDDM功能点, 移相器相关的bring up 需要包含以下环节:

* 配置与工作状态
 - Alpha solution相关:
  + DDM slots: 0b1111001010010100 (与CFAR/DOA 的调度及数据流相互影响制约)
  + 脉冲参数: 76.5GHz 正负475MHz, 24us周期, MBC
  + 每个通道使用不超过4bit深度
 - 底层:
  + 移相器校准     (phase_cal/amp_cal)
  + 其他相关配置   (PA, PSBUF, LDO, etc)
* 校准
 - bench校准/lab校准
 - 原理及数据处理; 参数条件; CLI
* 特性: analog bench test向system交付; system lab test向solution交付
 - 单通道幅相误差       (bench  -> lab test)
 - 通道间互     耦问题       (bench  -> lab test)
 - 移相器稳态问题       (bench  -> lab test)
 - 芯片间互耦问题       (bench? -> lab test; 级联新问题, 需要硬件相关隔离设计)
    - 各方向响应问题                 (lab test)
    - 脉冲幅度差问题       (simlate-> lab test & solution tuning; 级联新问题)
* 依赖/集成
    - 前端波形及模式功能
 - 采数功能
 - 级联收发功能
 - 天线校准功能
 - MBC功能
* 延申
 - 7bit实际性能. (当前的方案一般只考虑同时使用同一TXPS的4bit状态. 对于7bit全部使用时的实际性能测试分析尚不充足. 目前有少数迹象显示, 使用更多bit时DDM旁瓣变差)
* 性能参数
 - ~30dB @ 4TDDM, cycle 8 on A0 TT corner, calibrated
    - ~26dB @ 8TDDM, cycle 16 on A0 TT corner, calibrated


对照上述清单, 介绍部分A0 验证中移相器条目遇到过的部分问题(这里就不详细列举时间节点了)

* 工艺参数问题
    - 不同process corner下TLPS移相器误差不同
    - System验证时缺少相关知识, 早期验证使用FF芯片, 效果较差
* 配置/工作状态问题
    - 早期设计的12us脉冲周期波形不满足移相器稳态时间, 效果较差
    - PA配置, 由于LODIST震荡问题调整默认值, PA工作状态不饱和, 导致移相器幅度响应差异大, 效果较差
    - PSLDO/PSBUF配置问题, 由于前述原因调整默认值, PA增益变大, 可能导致非线性增强
* 驱动问题
    - 受测试过程和资源限制, system lab test过程中, 较少及时同步远程代码
    - 调整上述底层配置问题时, 主要通过system手动修改driver相关参数实现
    - 不熟悉radio driver结构, 错误改动风险大, 效率低; 有效改动不能及时commit
* 工具链问题
    - DCK链路不稳定; Jtag debug mode 测试效率较低
* 反馈问题
    - 22年3月初, System在Alps上实验证实了移相器通道间耦合问题
    - 22年8月底, System在Andes A0上确认了通道间耦合问题
    - 22年12月,  System与Analog designer逐步同步了通道间耦合问题的认识
    - 23年1月底, System向Analog交付了通道间耦合问题的测试方法

这个例子中, designer和user (system, 以及M0BU中solution team)的沟通是偏少的: 在模块工作状态(ConOps)上存在信息差, 多轮lab测试实际无效; 在交付验证方法上存在预期差, 交换结论的效率不高. 正因如此, 我们希望能够凭借回片前相对深入的沟通和计划改善M0 bring up的效率. 同时, 事前计划不能替代事中的协作. 如文婷此前指出, 针对异常现象的测试分析手段往往是随机应变的; 分析得到的新知识新结论, 也会改变原定的测试条目.

==============

无论是详细计划的制定, 还是高效的迭代测试和交付验收, 都需要熟悉情况的工程师之间频繁和积极的跨部门交互, 不太可能仅凭一级主管间的讨论达成. 回片前的计划制定, 不单产出BU计划, 也调整部门协作形态, 使得上下游的配合模式能够比以往更加主动地应对BU过程中的各种意外情况.

在前面的例子中我们已经看到了, 下游部门尽早介入上游工作(即便只是存在性地介入), 上游部门更多了解下游完整需求, 对双方的工作都是有益处的.

在FPGA验证等工作中, 已经采取了项目相关工程师定期align的形式; 这种做法比起临时交互, 了解背景, 构建共同语境要相对高效一些. 我尝试在A0 系统验证阶段简单复制这种形式, 并没有取得成效, 主要由于我知识背景不足; 同时A0功能范畴广, 涉及的工程师更多, 功能节点关系更复杂, 如果采用集体align形式, 范围较大, 效率较低. 如果按照进一步功能点划分组织项目组的形式, 可能可以从一定程度上改善这个问题.

==============

BB算法案例: 管理需求内容, 快速应对需求变化

相比前端部分, 对BB bring up部分的思考更多从整体的角度出发. 目前对基带算法各个引擎的验证相对充分, sequencer调度和BBUF交互也已经基本掌握. 然而, 要向solution team交付"完整易用的基带算法功能", 仍需要完成以下内容:

* 面向两片级联Alpha solution的完整SIL playback
* 可读易用的bb driver配置界面
    - 回片前, 完成配置界面的参数定义, 以及根据配置参数计算寄存器值的工作
    - 优先覆盖Alpha solution相关功能
* BB-DSP交互环节以及DSP算法的完整实现
    - DSP算法实现及优化
    - DSP计算时间评估及优化
    - 与CFAR/DOA的调度配合优化
* 梳理多种CFAR/DSP/DOA算法和数据流组合的需求
    - 根据Alpha solution基本要求, 实现距离分段采用不同CFAR等调度
* CFAR - DSP - DOA的模块化封装, 以支持对多种组合的需求
    - 根据Alpha solution调试需求,
* 多重算法组合与片间数据交互的集成

==============

最后介绍一下一些预期中system在Andes M0 bring up中的各项任务.

< img src="bring_up_tasklist.png" width=600>

从时间上看, 将工作分为了回片前, 回片后和PES长期验证三个阶段.

首先, 在三月底之前, system会基于BB/A0验证中掌握的知识和情况, 支持solution尽可能详细完整地设计Alpha solution, 并对定义芯片相关功能的运作方式和验收方式.

在回片前, system希望就前述BB交付存在的问题做一系列的准备, 包括SIL准备, BB driver及模块化; 同时支持solution基于A0开展方案验证. 对于M0前端验证, 主要同相关工程师制定回片后的测试内容, 策略和环境.

回片后, System会基于A0经验和计划同Analog接力开展信号质量验证(bench/system lab test)并向solution交付可用的ADC数据, 各项前端性能测试论证过程, 及其对solution性能的影响或制约; 基带方面, 除回归各项FPGA测试确保计算正确之外, 配合solution对Alpha solution涉及的各项算法性能做综合或专门测试. 预期这些工作的有效交付验收, 能够较好地支持Alpha solution的开发, 验证和调试.

在完整可用, 性能达标的alpha solution之后, system预计需要对Andes M0的性能做进一步挖掘, 例如是对数字前端/RF控制中M0新增功能做测试验证; 将CQM + DSP恢复等有潜力有价值的功能进一步集成到Alpha solution中, 等.

在三个阶段中, 都需要与FW/STE/Solution就测试验证工具链的持续交互.

以上仍是一个比较粗略的过程, 需要在频繁的多边协调中, 对各个功能点完成如DDM旁瓣-移相器性能一样的详细描述和计划. 希望今天的说明, 能够给M0 bring up 计划的制定提供一些参考.

谢谢大家.
===============

这样一个瞎开炮的会议, 我人在深圳, 没法现场交流和获取反馈, 十分尴尬. 讨论非常有限, 基本可以认为这个讲法没有形成影响.

嘉澍的意见是, ASPICE已经提供了完整的研发框架, 只要严格按照das V-model在一年前完成功能拆分和定义测试项, 在一年后完成相关测试项, 这个产品就顺利开发完成了, 不需要重新组织测试过程, 也不需要强调早期价值交付.

Andes没有引入ASPICE模型, Alps Pro才开始的, 当时的提法应该是FW先行, 有效果推广到全公司, 不知道是不是珉楠的意思. CMM, SPICE和ASPICE是一脉相承的东西, 我作为一个认同技术实践而不认同流程管控的人, 天然不认同ASPICE.

我的主要感受是困惑: 虽然提出了M0一月完成bring up的目标, 但看不到来自顶层的具体举措来推进; 之前的目标完不成, 也渐渐作为一种常态被接受. 回到这个例子, 我完全不相信ASPICE能够解决问题: 朱砚最早在起草Andes时的三个条件: 100MHzADC, BWE可用, 128脉冲完成8通道DDM, 全部不成立, 所以Andes完全无法以当初朱砚设计的方式达成预定指标. ASPICE要怎么应对这种问题? 全部列为关键风险, 并且制订备份方案?

流程应当依附于辨识和解决问题, 不能有独立性. 否则一定会引入目标的双重性: 究竟是达成任务, 还是以规定的方法达成任务? 如果流程规定的方法有价值, 那么一定可以明确地描述其所要达成的任务和检验方法, 完全可以与技术/产品任务对等管理, 不需要用额外的框架消耗精力. 而不能明确定义自身任务和目标的流程, 一定是神棍. "听我的一定能规避问题, 具体什么问题你碰上了就知道了". 这特么的和算命跳大神有什么区别. 从这个意义上失败的流程和失败的产品开发真是一脉相承: 提出不需要经过检验的需求, 然后认真地满足它.

**20220305**

在Andes的PTO test matrix review会上气氛可以说是死气沉沉, 没有人有把工作拿出来展示的准备; 也没有人有能力检验展示. 我一直的信条是, "如果你不能发现我在骗你, 那你就没有资格要求我展示我的工作". 

可以从几个方面证明这个会议的失败. 既然是PTO review, 那么这个会的结论就是可以tapeout或者不可以. 我们有没有可能接受一个不能tapeout, 需要继续delay的结论? 不可能, 所以这个会的结论已经注定了, 只是一个形式. 有两个细节很能证明这种形式性. 一个是针对一验证不通过项目, 产品owner洪泉的反馈是"我没有意见, 这个时间我也不可能有意见"; 另一个是当项目经理水文提出"一些test matrix条目没有结论时"技术的反馈是"这就是个频率值不用测试". 然后就没有然后了. 这是不是一个问题? 流程又怎么解决这种问题? 是调整test matrix条目的范围和生成方法, 还是做出特别的标注? 还是向PM提供相关的常识? 流程不会对此做出反应; 人可以, 但被流程搞得疲于奔命的人不行, 所以我们一定会看到同样的无意义对话以同样的passive aggressive的语气再次发生.
