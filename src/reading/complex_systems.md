# Readins on complex systems

频繁看到关于复杂系统的话题. 把相关的阅读都整理到这个页面下

## [How complex systems fail](https://how.complexsystems.fail/)

* 这篇文章的作者Richard Cook来自芝加哥大学"认知技术实验室". 他对"复杂系统失效"的分析也是非具体的.
* \[1\]风险是复杂系统的固有特征. \[5\]复杂系统通常总是在不断演变的非理想状态下运行: 需求的变化, 时效压力, 组件迭代, 维护缺位, 决定了系统没有一个静态的理想状态, 更不可能简单地向这一目标收敛.
* \[3\]系统崩溃往往是多重失效的复合结果. \[4\]在见证这种组合效应之前, 设计者很难预判系统的失效方式并予以完全的预防. \[2\]正常工作的复杂系统往往通过冗余保护来分隔各个失效. 这种被动防御一方面起到很好的效果, \[6\]另一方面永远是不充分的.
* \[7\]作者就此指出: 事后的"根因分析"是一种错误的做法, 尤其是唯一根因分析: 暴露出的系统的问题是多重隐性问题的组合. 归因更多是人们"找出一个被指责的对象"的心理需要在作祟. \[8\]而且往往收到后视镜偏见的影响: "怎么连这个都没想到", "这种做法下灾难是不可避免的". \[15\]针对系统问题打补丁时, 由于系统泵困本身是多重因素以特定方式共振引起的小概率事件, 如果不小心评估和控制改动引起的额外耦合, 这些补丁可能反倒增加出问题的概率和定位难度.
* \[9\]复杂系统中的操作者同时肩负两方面的任务: 一方面维持系统的日常运转和产出, 另一方面规避可能放生的风险. 安全是要牺牲效率换取的. 外来视角常常在不出问题时低估风险强调效率, 而在事故后高估风险强调安全. \[10\] 基于复杂系统自身某种程度的不可知性, 以及两种任务的权衡, 所有干预和操作总有赌博的色彩. \[11\]甚至于, 在采取行动以前, 整个系统的目标, 安全还是效率, 都是混沌而模糊的, 连一团可以描述的概率云都不是. 人为干预和操作在各个环节消除这种模糊性, 使系统坍缩到一个具体的状态.
* \[16\]与系统的功能性一样, 系统的安全性也是一个"涌现性质", 不是各个组件兴致的简单叠加.
* \[12\]\[13\]\[14\]\[17\]\[18\]略

## Drift into failure [Link 1](https://sidneydekker.stackedsite.com/wp-content/uploads/sites/899/2013/01/DekkerDriftRiskChapter2013.pdf) [Link 2](https://safetydifferently.com/wp-content/uploads/2014/08/SDDriftPaper.pdf)

* Griffith大学Sidney Dekker题为"Drift into failure"的论文, 似乎有两个版本; 另有一本同名书籍, 可能补充了一些案例. 他个人网站中的论文很快切入了"高斯联合分布"和"危机中相关性变为1"的话题, 先从这个读起.
